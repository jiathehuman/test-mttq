# Nginx Load Balancer Configuration for MQTT Broker Cluster
#
# High-availability load balancer configuration providing transparent failover
# for MQTT clients connecting to a distributed broker cluster. Implements
# intelligent routing with health monitoring, weighted distribution, and
# automatic failover between healthy brokers.
#
# Key Features:
# - TCP stream load balancing for MQTT protocol (port 1883)
# - HTTP health monitoring endpoints for operational visibility
# - JSON-structured logging for integration with log aggregation systems
# - Weighted round-robin distribution based on broker priority
# - Automatic failover with backup server designation
# - Real-time health status proxying to monitoring service
#
# Architecture:
# - Stream module handles TCP load balancing for MQTT connections
# - HTTP module provides health endpoints and dashboard proxying
# - Upstream configuration defines broker cluster with failover weights
# - Health check integration with Python monitoring service

# Load stream module for Layer 4 (TCP/UDP) load balancing
# Required for MQTT protocol load balancing since MQTT operates over TCP
load_module modules/ngx_stream_module.so;

# Event processing configuration
# Defines the maximum number of simultaneous connections per worker process
events {
    worker_connections 1024;  # Adequate for typical MQTT client loads
}

# HTTP server configuration for health monitoring and dashboard access
# Provides operational endpoints and proxy functionality for monitoring services
http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    # Structured JSON logging configuration for operational monitoring
    # Enables integration with log aggregation systems (ELK, Splunk, etc.)
    # Captures essential metrics: response times, upstream health, client info
    log_format json_combined escape=json '{'
        '"timestamp":"$time_iso8601",'           # ISO 8601 timestamp
        '"remote_addr":"$remote_addr",'          # Client IP address
        '"request":"$request",'                  # HTTP request line
        '"status":$status,'                      # HTTP response status
        '"bytes_sent":$bytes_sent,'              # Response size in bytes
        '"http_referer":"$http_referer",'        # HTTP referer header
        '"http_user_agent":"$http_user_agent",'  # User agent string
        '"request_time":$request_time,'          # Total request processing time
        '"upstream_addr":"$upstream_addr",'      # Backend server address
        '"upstream_status":"$upstream_status",'  # Backend response status
        '"upstream_response_time":"$upstream_response_time"'  # Backend response time
    '}';

    # Health monitoring and administrative interface server block
    # Provides endpoints for load balancer health checks and service integration
    server {
        listen 8080;                    # Non-standard port to avoid conflicts
        server_name localhost;          # Accept requests to localhost only

        # Separate log files for health monitoring traffic
        access_log /var/log/nginx/health_access.log json_combined;
        error_log /var/log/nginx/health_error.log;

        # Load balancer health status endpoint
        # Used by monitoring systems to verify nginx operational status
        location /health {
            access_log off;                    # Reduce log noise from health checks
            return 200 "healthy\n";            # Simple health confirmation
            add_header Content-Type text/plain;
        }

        # MQTT cluster health status proxy endpoint
        # Forwards health requests to Python monitoring service for cluster status
        location /mqtt-health {
            access_log off;                             # Reduce log verbosity
            proxy_pass http://localhost:5000/health;    # Python health service
            proxy_set_header Host $host;                # Preserve original host
            proxy_set_header X-Real-IP $remote_addr;   # Forward client IP
        }

        # Dashboard proxy
        location / {
            proxy_pass http://localhost:3000;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # WebSocket support for dashboard
        location /socket.io/ {
            proxy_pass http://localhost:3000;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }
    }
}

# Stream configuration for MQTT load balancing
stream {
    # Define upstream servers with health checks
    upstream mqtt_brokers {
        # Primary broker (highest priority)
        server 192.168.64.2:1883 weight=5 max_fails=3 fail_timeout=30s;

        # Backup brokers (sequential priority)
        server 192.168.64.3:1883 weight=4 max_fails=3 fail_timeout=30s backup;
        server 192.168.64.4:1883 weight=3 max_fails=3 fail_timeout=30s backup;
        server 192.168.64.5:1883 weight=2 max_fails=3 fail_timeout=30s backup;
        server 192.168.64.6:1883 weight=1 max_fails=3 fail_timeout=30s backup;        # Least connections load balancing
        least_conn;
    }

    # MQTT load balancer
    server {
        listen 1883;
        proxy_pass mqtt_brokers;

        # Connection settings optimized for MQTT
        proxy_timeout 60s;
        proxy_connect_timeout 5s;
        proxy_responses 1;  # MQTT is typically request-response

        # Enable session persistence (sticky sessions)
        # This helps maintain MQTT session state
        proxy_bind $remote_addr transparent;

        # Logging
        access_log /var/log/nginx/mqtt_access.log;
        error_log /var/log/nginx/mqtt_error.log;
    }

    # Health check for MQTT brokers (TCP check)
    server {
        listen 1884;
        proxy_pass mqtt_brokers;
        proxy_timeout 3s;
        proxy_connect_timeout 1s;
        access_log off;
    }
}

# Additional configurations for different environments
# Uncomment and modify as needed

# For production with SSL/TLS:
# stream {
#     upstream mqtt_brokers_ssl {
#         server 192.168.100.10:8883 weight=5 max_fails=3 fail_timeout=30s;
#         server 192.168.100.11:8883 weight=4 max_fails=3 fail_timeout=30s backup;
#         server 192.168.100.12:8883 weight=3 max_fails=3 fail_timeout=30s backup;
#         server 192.168.100.13:8883 weight=2 max_fails=3 fail_timeout=30s backup;
#         server 192.168.100.14:8883 weight=1 max_fails=3 fail_timeout=30s backup;
#     }
#
#     server {
#         listen 8883 ssl;
#         ssl_certificate /path/to/cert.pem;
#         ssl_certificate_key /path/to/key.pem;
#         proxy_pass mqtt_brokers_ssl;
#         proxy_timeout 60s;
#         proxy_connect_timeout 5s;
#     }
# }